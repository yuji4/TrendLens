import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import warnings

warnings.filterwarnings("ignore")

# ===============================
# ë‚´ë¶€ ëª¨ë“ˆ Import
# ===============================
from analysis.api_manager import get_naver_trend_data
from analysis.data_manager import save_data_to_csv, load_latest_csv, merge_all_csv
from analysis.modeling import run_ccf_analysis
from components.ui_components import render_sidebar, setup_scheduler
from report.pdf_generator import generate_trend_report
from analysis.trend_events import detect_surge_events
from analysis.news_fetcher import fetch_news_articles
from analysis.ai.ai_cause_analysis import analyze_news_articles
from ui.model_ui import render_prophet_ui, render_arima_ui, render_random_forest_ui, render_model_info
from ui.metrics_ui import render_metrics_comparison
from ui.correlation_ui import render_correlation_ui


# ===============================
# ì „ì—­ ì‹œê°í™” ìŠ¤íƒ€ì¼
# ===============================
PLOTLY_STYLE = dict(
    plot_bgcolor="white",
    paper_bgcolor="white",
    font=dict(size=14, color="#212121"),
    hovermode="x unified",
    margin=dict(l=40, r=30, t=60, b=40),
    legend=dict(orientation="h", y=-0.2)
)

# ===============================
# ê¸°ë³¸ ì„¤ì • ë° ìŠ¤íƒ€ì¼
# ===============================
st.set_page_config(page_title="TrendLens - ë„¤ì´ë²„ íŠ¸ë Œë“œ ë¶„ì„", layout="wide")

st.markdown(
    """
    <style>
    h1 {
        text-align: center;
        color: #0D47A1;
        font-size: 36px !important;
        margin-bottom: 10px;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 10px;
    }
    .stTabs [data-baseweb="tab"] {
        background-color: #E3F2FD;
        border-radius: 10px;
        padding: 8px 20px;
        font-weight: 600;
    }
    .stTabs [aria-selected="true"] {
        background-color: #1976D2 !important;
        color: white !important;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

st.title("ğŸ‘€ TrendLens: ë„¤ì´ë²„ ê²€ìƒ‰ íŠ¸ë Œë“œ ë¶„ì„")


# ===============================s
# âš™ï¸ ì‚¬ì´ë“œë°” ë Œë”ë§ ë° ì„¤ì • ê°’ ë¡œë“œ
# ===============================
keywords, time_unit, start_date, end_date, align_option, update_btn, merge_btn = render_sidebar()

if not keywords:
    st.warning("ê²€ìƒ‰ì–´ë¥¼ 1ê°œ ì´ìƒ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()


# ===============================
# ğŸ“¦ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
# ===============================
df = None

if update_btn:
    # í‚¤ì›ŒíŠ¸ ì„¸íŠ¸ ë³€ê²½ ì‹œ, ì´ì „ ì˜ˆì¸¡ ê¸°ë¡ ì´ˆê¸°í™”
    if "model_metrics" in st.session_state:
        st.session_state["model_metrics"].clear()
        st.info("ğŸ”„ í‚¤ì›Œë“œ ì„¸íŠ¸ ë³€ê²½ ê°ì§€: ê¸°ì¡´ ëª¨ë¸ ì„±ëŠ¥ ë°ì´í„° ì´ˆê¸°í™” ì™„ë£Œ")

    with st.spinner("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
        try:
            data = get_naver_trend_data(
                keywords=keywords,
                start_date=str(start_date),
                end_date=str(end_date),
                time_unit=time_unit,
            )
            if not data or "results" not in data:
                st.error("ì„ íƒí•œ ì¡°ê±´ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                file_path = save_data_to_csv(data)
                st.success(f"âœ… ìµœì‹  ë°ì´í„° ì €ì¥ ì™„ë£Œ: {file_path}")
                df = load_latest_csv() 
        except Exception as e:
            st.error(f"ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")

df = load_latest_csv() if df is None else df

if merge_btn:
    merged = merge_all_csv()
    if merged.empty:
        st.warning("ë³‘í•©í•  CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        df = merged
        st.success(f"ğŸ—‚ CSV ë³‘í•© ì™„ë£Œ")

if df is not None and not df.empty:
    df["date"] = pd.to_datetime(df["date"])
    df = df.sort_values("date")
    if align_option == "ê³µí†µ ë‚ ì§œ":
        df = df.dropna(subset=[c for c in df.columns if c != "date"])


# ===============================
# ğŸ“Š ë©”ì¸ íƒ­ 
# ===============================
if df is not None and not df.empty:
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "ğŸ“Š íŠ¸ë Œë“œ ë¹„êµ",
        "ğŸ“ˆ ìƒì„¸ ë¶„ì„",
        "ğŸ”— ìƒê´€ ë¶„ì„",
        "ğŸ”® íŠ¸ë Œë“œ ì˜ˆì¸¡",
        "ğŸ“Š ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ",
        "â¬‡ï¸ ë‹¤ìš´ë¡œë“œ"
    ])

    # --- íƒ­ 1: íŠ¸ë Œë“œ ë¹„êµ ---
    with tab1:
        st.caption("ì„ íƒí•œ í‚¤ì›Œë“œë³„ ê²€ìƒ‰ëŸ‰ ì¶”ì´ë¥¼ ì´ë™í‰ê· ì„ ì ìš©í•˜ì—¬ ë¶€ë“œëŸ½ê²Œ ë¹„êµí•©ë‹ˆë‹¤.")
        st.subheader("ğŸ“Š í‚¤ì›Œë“œë³„ íŠ¸ë Œë“œ ë³€í™”")
        smooth_window = st.slider("ì´ë™í‰ê·  ê¸°ê°„", 1, 14, 1, 1)

        df_vis = df.copy()
        if smooth_window > 1:
            value_cols = [c for c in df.columns if c != "date"]
            df_vis[value_cols] = df_vis[value_cols].rolling(window=smooth_window, min_periods=1).mean()

        df_long = df_vis.melt(id_vars="date", var_name="keyword", value_name="ratio")
        fig = px.line(df_long, x="date", y="ratio", color="keyword", markers=True)
        fig.update_layout(**PLOTLY_STYLE)
        st.plotly_chart(fig, width='stretch')
        st.dataframe(df_vis, width='stretch')

    # --- íƒ­ 2: ìƒì„¸ ë¶„ì„ ---
    with tab2:
        st.caption("ê²€ìƒ‰ëŸ‰ ê¸‰ë“± ì´ë²¤íŠ¸ë¥¼ ìë™ ê°ì§€í•˜ê³ , í‚¤ì›Œë“œ ê´€ë ¨ ë‰´ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ AIê°€ ì›ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.")
        st.subheader("ğŸ“ˆ ê¸‰ë“± ì´ë²¤íŠ¸ ë¶„ì„")

        # 1) ê¸‰ë“± ì´ë²¤íŠ¸ ê°ì§€
        events = detect_surge_events(df, threshold_percent=50)

        if events.empty:
            st.info("ğŸ“‰ ê¸‰ë“± ì´ë²¤íŠ¸ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        else:
            st.success(f"ì´ {len(events)}ê°œì˜ ê¸‰ë“± ì´ë²¤íŠ¸ ê°ì§€ë¨")
            st.dataframe(events, width='stretch')

            # ì„ íƒë°•ìŠ¤ ë§Œë“¤ê¸°
            max_change_indices = events.groupby('keyword')['change'].idxmax()
            max_events = events.loc[max_change_indices]
            event_key_list = max_events.apply(
                lambda r: f"{r['keyword']} | +{r['change']}%",
                axis=1
            )
            selected = st.selectbox("ë¶„ì„í•  ì´ë²¤íŠ¸ ì„ íƒ", event_key_list)

            # ì„ íƒëœ ë°ì´í„° ì°¾ê¸°
            keyword_to_find = selected.split(' | ')[0].strip()
            ev = max_events[max_events['keyword'] == keyword_to_find].iloc[0]

            keyword = ev["keyword"]
            change = ev["change"]

            st.info(f"ğŸ” ì„ íƒí•œ ì´ë²¤íŠ¸: **{keyword}** (ì¦ê°€ìœ¨ +{change}%)")

            if st.button("ğŸ“¡ ë‰´ìŠ¤ ìˆ˜ì§‘ + AI ì›ì¸ ë¶„ì„ ì‹¤í–‰"):
                with st.spinner("ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘..."):
                    articles = fetch_news_articles(
                        keyword, 
                        max_articles=100 
                    )

                if len(articles) == 0:
                    st.warning("ê´€ë ¨ ë‰´ìŠ¤ê°€ ë¶€ì¡±í•´ AI ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.success(f"{len(articles)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ë¨")

                    # 3) AI ë¶„ì„
                    with st.spinner("AIê°€ ê¸‰ë“± ì›ì¸ì„ ë¶„ì„í•˜ëŠ” ì¤‘..."):
                        cause_text = analyze_news_articles(keyword, articles)

                    st.warning("âš ï¸ **ë¶„ì„ ê²°ê³¼ ì•ˆë‚´:** ë„¤ì´ë²„ API ì •ì±…ìƒ ê³¼ê±° ê¸‰ë“± ì‹œì ì˜ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì•„ë˜ AI ë¶„ì„ì€ **ì„ íƒëœ í‚¤ì›Œë“œì˜ ê¸‰ë“± ì›ì¸**ì´ ì•„ë‹Œ, **í˜„ì¬ ì‹œì ì—ì„œ ê°€ì¥ ìµœê·¼ ë°œí–‰ëœ ë‰´ìŠ¤ë“¤**ì„ ê¸°ë°˜ìœ¼ë¡œ í•´ë‹¹ í‚¤ì›Œë“œê°€ ì–´ë–»ê²Œ í™œìš©ë˜ê³  ìˆëŠ”ì§€ì— ëŒ€í•œ **ìµœì‹  ë…¼ì ì„ ìš”ì•½**í•œ ê²ƒì…ë‹ˆë‹¤.")
                    st.markdown("### ğŸ”¥ ê¸‰ë“± ì›ì¸ ë¶„ì„ ê²°ê³¼")
                    st.write(cause_text)

                    st.markdown("### ğŸ“° ì°¸ì¡°ëœ ë‰´ìŠ¤")
                    for a in articles:
                        st.markdown(f"""
                        **{a['title']}**  
                        {a['desc']}  
                        ğŸ”— [ê¸°ì‚¬ ë³´ê¸°]({a['link']})
                        """)
                        st.divider()

    # --- íƒ­ 3: ìƒê´€ ë¶„ì„ ---
    with tab3:
        st.caption("í‚¤ì›Œë“œ ê°„ ê²€ìƒ‰ íŒ¨í„´ ìœ ì‚¬ë„ë¥¼ ìƒê´€ê³„ìˆ˜ ë° ë„¤íŠ¸ì›Œí¬ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
        st.subheader("ğŸ”— ìƒê´€ê´€ê³„ ë¶„ì„")

        render_correlation_ui(df, PLOTLY_STYLE)

    # --- íƒ­ 4: ì˜ˆì¸¡ ---
    with tab4:
        st.caption("Prophet / ARIMA / Random Forest ê¸°ë°˜ ë¯¸ë˜ ê²€ìƒ‰ íŠ¸ë Œë“œ ì˜ˆì¸¡ ë° ë¹„êµ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.")
        st.subheader("ğŸ”® íŠ¸ë Œë“œ ì˜ˆì¸¡")

        model_type = st.radio("ëª¨ë¸ ì„ íƒ", ["Prophet", "ARIMA", "Random Forest"], horizontal=True)
        render_model_info()

        selected_kw = st.selectbox(
            "ì˜ˆì¸¡í•  í‚¤ì›Œë“œ", [c for c in df.columns if c != "date"]
        )
        days_ahead = st.slider("ì˜ˆì¸¡ ê¸°ê°„ (ì¼)", 7, 180, 30, 7)

        # Prophet/ARIMA/RF ê³µí†µ ë°ì´í„° í¬ë§·(ds, y)
        df_forecast = df[["date", selected_kw]].rename(
            columns={"date": "ds", selected_kw: "y"}
        )

        # ê° ëª¨ë¸ì˜ UI ì²˜ë¦¬ í•¨ìˆ˜ í˜¸ì¶œ
        if model_type == "Prophet":
            render_prophet_ui(df_forecast, selected_kw, days_ahead)

        elif model_type == "ARIMA":
            render_arima_ui(df_forecast, selected_kw, days_ahead)

        elif model_type == "Random Forest":
            render_random_forest_ui(df_forecast, selected_kw, days_ahead)
        

    # --- íƒ­ 5: ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ---
    with tab5:
        st.caption("ì˜ˆì¸¡ ëª¨ë¸ë³„ ì •í™•ë„(MAPE, RMSE)ë¥¼ ë¹„êµí•˜ì—¬ ìµœì  ëª¨ë¸ì„ í™•ì¸í•©ë‹ˆë‹¤.")
        st.subheader("ğŸ“Š ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ ëŒ€ì‹œë³´ë“œ")
        
        df_metrics = pd.DataFrame(st.session_state.get("model_metrics", []))
        render_metrics_comparison(df_metrics, selected_kw, PLOTLY_STYLE)

    # --- íƒ­ 6: ë‹¤ìš´ë¡œë“œ ---
    with tab6:
        st.caption("ê²€ìƒ‰ ë°ì´í„° ë° ëª¨ë¸ ì„±ëŠ¥ ë¦¬í¬íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        st.subheader("â¬‡ï¸ ë°ì´í„° ë° ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ")

        csv = df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ğŸ’¾ ìµœì‹  ë°ì´í„° ë‹¤ìš´ë¡œë“œ", csv, "trend_data_latest.csv", "text/csv")

        st.divider()
        st.markdown("ğŸ’¾ ëª¨ë¸ ì„±ëŠ¥ ë¦¬í¬íŠ¸ (PDF ìƒì„±)")

        if "model_metrics" not in st.session_state or len(st.session_state["model_metrics"]) == 0:
            st.info("ëª¨ë¸ ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì˜ˆì¸¡ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        else:
            if st.button("ğŸ§¾ PDF ë¦¬í¬íŠ¸ ìƒì„±", type="primary"):
                try:
                    buffer = generate_trend_report(
                        df=df,
                        keywords=keywords,
                        start_date=start_date,
                        end_date=end_date,
                        time_unit=time_unit,
                        model_metrics=st.session_state.get("model_metrics", [])
                    )
                    
                    st.download_button(
                        label="ğŸ“¥ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ (PDF)",
                        data=buffer,
                        file_name=f"TrendLens_Report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                        mime="application/pdf"
                    )
                    st.success("âœ… PDF ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
                    
                except Exception as e:
                    st.error(f"PDF ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

else:
    st.info("ì¢Œì¸¡ì—ì„œ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ê³  'ì—…ë°ì´íŠ¸'ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

# ===============================
# â° ìë™ ì—…ë°ì´íŠ¸ ìŠ¤ì¼€ì¤„ëŸ¬
# ===============================
setup_scheduler()
