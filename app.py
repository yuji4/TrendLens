import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
import networkx as nx
import optuna
from datetime import date, timedelta, datetime
from apscheduler.schedulers.background import BackgroundScheduler
import atexit, os, glob, warnings
from prophet import Prophet
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.stattools import ccf
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
from reportlab.lib.units import cm
from reportlab.lib import colors
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.cidfonts import UnicodeCIDFont

warnings.filterwarnings("ignore")
pdfmetrics.registerFont(UnicodeCIDFont('HYSMyeongJo-Medium'))

# ë‚´ë¶€ ëª¨ë“ˆ 
from analysis.api_manager import get_naver_trend_data
from analysis.data_manager import save_data_to_csv, load_latest_csv, merge_all_csv

# ===============================
# ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° í•¨ìˆ˜
# ===============================
def mean_absolute_percentage_error(y_true, y_pred):
    epsilon = 1e-10
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / (y_true + epsilon))) * 100

def root_mean_squared_error(y_true, y_pred):
    return np.sqrt(mean_squared_error(y_true, y_pred))

# ===============================
# ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•¨ìˆ˜ (Random Forest)
# ===============================
def create_features(df: pd.DataFrame) -> pd.DataFrame:
    """ë‚ ì§œ(ds) ì»¬ëŸ¼ì—ì„œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ ì‹œê°„ í”¼ì²˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    df['dayofweek'] = df['ds'].dt.dayofweek    # ìš”ì¼
    df['month'] = df['ds'].dt.month            # ì›”
    df['year'] = df['ds'].dt.year              # ì—°ë„
    df['dayofyear'] = df['ds'].dt.dayofyear    # ì—°ë„ ë‚´ ì¼ìˆ˜ 
    
    if 'time_index' not in df.columns:
        df['time_index'] = np.arange(len(df))
        
    return df

@st.cache_data
def tune_random_forest_bayesian(X_train, y_train, n_trials=25):
    # Optuna ê¸°ë°˜ ë² ì´ì§€ì•ˆ ìµœì í™”ë¡œ RandomForest í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
    def objective(trial):
        params = {
            "n_estimators": trial.suggest_int("n_estimators", 100, 400),
            "max_depth": trial.suggest_int("max_depth", 3, 15),
            "min_samples_split": trial.suggest_int("min_samples_split", 2, 10),
            "min_samples_leaf": trial.suggest_int("min_samples_leaf", 1, 5),
            "max_features": trial.suggest_float("max_features", 0.5, 1.0),
            "random_state": 42,
            "n_jobs": -1,
        }
        model = RandomForestRegressor(**params)
        scores = cross_val_score(
            model, X_train, y_train, 
            scoring="neg_mean_squared_error", cv=3, n_jobs=-1
        )
        return -np.mean(scores)  # ìµœì†Œí™”ëœ MSE
    
    study = optuna.create_study(direction="minimize")
    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)

    best_params = study.best_params
    best_model = RandomForestRegressor(**best_params)
    best_model.fit(X_train, y_train)

    return best_model, best_params, study.best_value

def run_random_forest(df: pd.DataFrame, days: int, tuned_model=None):

    # 1. í•™ìŠµ ë°ì´í„° í”¼ì²˜ ìƒì„±
    train_df = create_features(df.copy())
    
    # 2. ë¯¸ë˜ ë°ì´í„°ì…‹ ì¤€ë¹„ ë° í”¼ì²˜ ìƒì„±
    last_date = df['ds'].iloc[-1]
    future_dates = pd.date_range(start=last_date, periods=days + 1, freq='D')[1:]
    future_df = pd.DataFrame({'ds': future_dates})
    future_df = create_features(future_df)
    
    # time_index ì—°ì†ì„± ìœ ì§€
    last_index = train_df['time_index'].iloc[-1]
    future_df['time_index'] = np.arange(len(future_df)) + last_index + 1
    
    # 3. ëª¨ë¸ í•™ìŠµ
    features = [c for c in train_df.columns if c not in ['ds', 'y']] 
    X_train, y_train = train_df[features], train_df['y']
    
    if tuned_model is not None:
        model = tuned_model
    else: 
        model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
        model.fit(X_train, y_train)
    
    # 4. ì˜ˆì¸¡ (ê³¼ê±° ì í•©ë„ ë° ë¯¸ë˜ ì˜ˆì¸¡)
    y_pred_past = model.predict(X_train) 
    X_future = future_df[features]
    y_pred_future = model.predict(X_future)
    
    # 5. í”¼ì²˜ ì¤‘ìš”ë„ ì¶”ì¶œ
    feature_importances = model.feature_importances_
    
    # ê²°ê³¼ í†µí•© (Streamlit ì‹œê°í™”ìš©)
    future_result = future_df[['ds']].rename(columns={'ds': 'ë‚ ì§œ'})
    future_result['ì˜ˆì¸¡ê°’'] = y_pred_future
    
    # ë°˜í™˜ê°’ ë³€ê²½: future_result, y_true, y_pred_past, feature_importances, features ëª©ë¡ ë°˜í™˜
    return future_result, y_train.values, y_pred_past, feature_importances, features

# ===============================
# ëª¨ë¸ ì„±ëŠ¥ ê¸°ë¡ í•¨ìˆ˜
# ===============================
def save_model_metrics(model_name, keyword, mape, rmse):
    if "model_metrics" not in st.session_state:
        st.session_state["model_metrics"] = []

    st.session_state["model_metrics"].append({
        "í‚¤ì›Œë“œ": keyword,
        "ëª¨ë¸ëª…": model_name,
        "MAPE(%)": round(mape, 2),
        "RMSE": round(rmse, 4),
        "ê¸°ë¡ì‹œê°„": datetime.now().strftime("%H:%M:%S")
    })

# ===============================
# ìë™ ì—…ë°ì´íŠ¸ í•¨ìˆ˜
# ===============================
def auto_update_job():
    try:
        keywords = ["ë´„", "ì—¬ë¦„", "ê°€ì„", "ê²¨ìš¸"]
        today = date.today()
        start = today - timedelta(days=7)
        data = get_naver_trend_data(
            keywords=keywords,
            start_date=str(start),
            end_date=str(today),
            time_unit="date",
            gender="",
        )
        if data and "results" in data:
            file_path = save_data_to_csv(data)
            st.session_state["last_update_time"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            print(f"âœ… [ìë™ ìˆ˜ì§‘ ì™„ë£Œ] {file_path}")
        else:
            print("âš ï¸ [ìë™ ìˆ˜ì§‘ ì‹¤íŒ¨] ì‘ë‹µ ì—†ìŒ")
    except Exception as e:
        print(f"âŒ ìë™ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")

# ===============================
# ì‹¤ì‹œê°„ ìë™ ìƒˆë¡œê³ ì¹¨ ì˜µì…˜
# ===============================
st.sidebar.markdown("### âš¡ ì‹¤ì‹œê°„ ëª¨ë“œ ì„¤ì •")

# ìƒˆë¡œê³ ì¹¨ ê°„ê²©(ì´ˆ ë‹¨ìœ„)
refresh_interval = st.sidebar.slider("ìë™ ìƒˆë¡œê³ ì¹¨ ì£¼ê¸° (ì´ˆ)", 30, 600, 60, step=30)
enable_live = st.sidebar.toggle("ì‹¤ì‹œê°„ ë°ì´í„° ê°±ì‹  í™œì„±í™”", value=False, help="ë„¤ì´ë²„ íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ê°±ì‹ í•©ë‹ˆë‹¤.")

if enable_live:
    st.sidebar.success(f"âœ… ì‹¤ì‹œê°„ ëª¨ë“œ ON ({refresh_interval}ì´ˆ ê°„ê²©)")
    st.sidebar.caption(f"ë§ˆì§€ë§‰ ìƒˆë¡œê³ ì¹¨: {datetime.now().strftime('%H:%M:%S')}")

    st.markdown(
        f"""
        <script>
        setTimeout(function() {{
            window.location.reload();
        }}, {refresh_interval * 1000});
        </script>
        """,
        unsafe_allow_html=True,
    )

else:
    st.sidebar.info("â¸ ì‹¤ì‹œê°„ ëª¨ë“œ ë¹„í™œì„±í™” ì¤‘")

# ===============================
# ì „ì—­ ì‹œê°í™” ìŠ¤íƒ€ì¼
# ===============================
PLOTLY_STYLE = dict(
    plot_bgcolor="white",
    paper_bgcolor="white",
    font=dict(size=14, color="#212121"),
    hovermode="x unified",
    margin=dict(l=40, r=30, t=60, b=40),
    legend=dict(orientation="h", y=-0.2)
)

# ===============================
# ê¸°ë³¸ ì„¤ì • ë° ìŠ¤íƒ€ì¼
# ===============================
st.set_page_config(page_title="TrendLens - ë„¤ì´ë²„ íŠ¸ë Œë“œ ë¶„ì„", layout="wide")

st.markdown(
    """
    <style>
    h1 {
        text-align: center;
        color: #0D47A1;
        font-size: 36px !important;
        margin-bottom: 10px;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 10px;
    }
    .stTabs [data-baseweb="tab"] {
        background-color: #E3F2FD;
        border-radius: 10px;
        padding: 8px 20px;
        font-weight: 600;
    }
    .stTabs [aria-selected="true"] {
        background-color: #1976D2 !important;
        color: white !important;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

st.title("ğŸ‘€ TrendLens: ë„¤ì´ë²„ ê²€ìƒ‰ íŠ¸ë Œë“œ ë¶„ì„")


# ===============================
# âš™ï¸ ì‚¬ì´ë“œë°”
# ===============================
with st.sidebar:
    st.markdown("### âš™ï¸ ê¸°ë³¸ ì„¤ì •")
    raw_keywords = st.text_input("ê²€ìƒ‰ì–´ ì…ë ¥ (ì‰¼í‘œë¡œ êµ¬ë¶„)", "ë´„, ì—¬ë¦„, ê°€ì„, ê²¨ìš¸")
    time_unit = st.selectbox("ë°ì´í„° ë‹¨ìœ„", ["date", "week", "month"])

    today = date.today()
    default_start = today - timedelta(days=90)
    start_date, end_date = st.date_input("ì¡°íšŒ ê¸°ê°„ ì„ íƒ", (default_start, today))

    gender_display = st.radio("ì„±ë³„ ì„ íƒ", ["ì „ì²´", "ë‚¨ì„±", "ì—¬ì„±"], horizontal=True)
    gender = {"ì „ì²´": "", "ë‚¨ì„±": "m", "ì—¬ì„±": "f"}[gender_display]

    st.divider()
    st.markdown("### ğŸ“Š ë°ì´í„° ì˜µì…˜")
    align_option = st.radio("ë‚ ì§œ ì •ë ¬ ê¸°ì¤€", ["ëª¨ë“  ë‚ ì§œ", "ê³µí†µ ë‚ ì§œ"], index=0)

    st.divider()
    st.markdown("### ğŸª„ ë°ì´í„° ê´€ë¦¬")
    colA, colB = st.columns(2)
    with colA:
        update_btn = st.button("ğŸ”„ ì—…ë°ì´íŠ¸", width='stretch')
    with colB:
        merge_btn = st.button("ğŸ—‚ CSV ë³‘í•©", width='stretch')

    st.divider()
    st.markdown("### ğŸ•’ ìë™ ìˆ˜ì§‘ ìƒíƒœ")
    if st.session_state.get("last_update_time"):
        st.success(f"ë§ˆì§€ë§‰ ìˆ˜ì§‘: {st.session_state['last_update_time']}")
    else:
        st.info("ìë™ ìˆ˜ì§‘ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("#### ğŸ“ˆ ìµœê·¼ ìë™ ìˆ˜ì§‘ ë¡œê·¸")
    csv_files = sorted(glob.glob("data/trend_data_*.csv"), key=os.path.getctime, reverse=True) if os.path.exists("data") else []
    log_df = pd.DataFrame([
        {"íŒŒì¼": os.path.basename(f), "ìƒì„±ì‹œê°": datetime.fromtimestamp(os.path.getctime(f))}
        for f in csv_files
    ])
    if not log_df.empty:
        log_df = log_df[log_df["ìƒì„±ì‹œê°"] > datetime.now() - timedelta(days=7)]
        for _, row in log_df.head(3).iterrows():
            st.markdown(
                f"<div style='font-size:13px; padding:4px 0;'>"
                f"ğŸ“‚ <b>{row['íŒŒì¼']}</b><br>"
                f"â° {row['ìƒì„±ì‹œê°'].strftime('%Y-%m-%d %H:%M:%S')}</div>",
                unsafe_allow_html=True,
            )
    else:
        st.caption("ìµœê·¼ ë¡œê·¸ ì—†ìŒ.")


# ===============================
# ğŸ“¦ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
# ===============================
keywords = [k.strip() for k in raw_keywords.split(",") if k.strip()]
if not keywords:
    st.warning("ê²€ìƒ‰ì–´ë¥¼ 1ê°œ ì´ìƒ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

df = None

if update_btn:
    with st.spinner("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
        try:
            data = get_naver_trend_data(
                keywords=keywords,
                start_date=str(start_date),
                end_date=str(end_date),
                time_unit=time_unit,
                gender=gender,
            )
            if not data or "results" not in data:
                st.error("ì„ íƒí•œ ì¡°ê±´ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                file_path = save_data_to_csv(data)
                st.success(f"âœ… ìµœì‹  ë°ì´í„° ì €ì¥ ì™„ë£Œ: {file_path}")
                df = load_latest_csv() # ë”ë¯¸ í•¨ìˆ˜ ì‚¬ìš©
        except Exception as e:
            st.error(f"ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")

if df is None:
    df = load_latest_csv()

if merge_btn:
    merged = merge_all_csv()
    if merged.empty:
        st.warning("ë³‘í•©í•  CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        merged_path = f"data/merged_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        df = merged
        st.success(f"ğŸ—‚ CSV ë³‘í•© ì™„ë£Œ")

if df is not None and not df.empty:
    df["date"] = pd.to_datetime(df["date"])
    df = df.sort_values("date")
    if align_option == "ê³µí†µ ë‚ ì§œ":
        df = df.dropna(subset=[c for c in df.columns if c != "date"])


# ===============================
# ğŸ“Š ë©”ì¸ íƒ­
# ===============================
if df is not None and not df.empty:
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "ğŸ“Š íŠ¸ë Œë“œ ë¹„êµ",
        "ğŸ“ˆ ìƒì„¸ ë¶„ì„",
        "ğŸ”— ìƒê´€ ë¶„ì„",
        "ğŸ”® íŠ¸ë Œë“œ ì˜ˆì¸¡",
        "ğŸ“Š ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ",
        "â¬‡ï¸ ë‹¤ìš´ë¡œë“œ"
    ])

    # --- íƒ­ 1: íŠ¸ë Œë“œ ë¹„êµ ---
    with tab1:
        st.caption("ì„ íƒí•œ í‚¤ì›Œë“œë³„ ê²€ìƒ‰ëŸ‰ ì¶”ì´ë¥¼ ì´ë™í‰ê· ì„ ì ìš©í•˜ì—¬ ë¶€ë“œëŸ½ê²Œ ë¹„êµí•©ë‹ˆë‹¤.")
        st.subheader("ğŸ“Š í‚¤ì›Œë“œë³„ íŠ¸ë Œë“œ ë³€í™”")
        smooth_window = st.slider("ì´ë™í‰ê·  ê¸°ê°„", 1, 14, 1, 1)

        df_vis = df.copy()
        if smooth_window > 1:
            value_cols = [c for c in df.columns if c != "date"]
            df_vis[value_cols] = df_vis[value_cols].rolling(window=smooth_window, min_periods=1).mean()

        df_long = df_vis.melt(id_vars="date", var_name="keyword", value_name="ratio")
        fig = px.line(df_long, x="date", y="ratio", color="keyword", markers=True)
        fig.update_layout(**PLOTLY_STYLE)
        st.plotly_chart(fig, width='stretch')
        st.dataframe(df_vis, width='stretch')

    # --- íƒ­ 2: ìƒì„¸ ë¶„ì„ ---
    with tab2:
        st.caption("ê¸‰ë“±Â·ê¸‰ë½ ë³€í™”ìœ¨ê³¼ ì •ê·œí™” ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
        st.subheader("ğŸ“ˆ ê¸‰ìƒìŠ¹Â·ê¸‰í•˜ë½ ë¶„ì„")

        view_mode = st.radio("ë¶„ì„ ë³´ê¸° ëª¨ë“œ", ["ì „ì²´ ìš”ì•½ ë³´ê¸°", "í‚¤ì›Œë“œë³„ ìƒì„¸ ë³´ê¸°"], horizontal=True)
        df2 = df.copy().set_index("date")
        pct = df2.pct_change().reset_index()
        pct.columns = ["date"] + [f"{c}_ì¦ê°ë¥ (%)" for c in df2.columns]
        for c in pct.columns[1:]:
            pct[c] = (pct[c] * 100).round(2)

        threshold = st.slider("ê¸‰ë³€ ê¸°ì¤€(%)", 10, 200, 50, 10)
        alerts = []
        for col in pct.columns[1:]:
            spikes = pct.loc[pct[col].abs() >= threshold, ["date", col]]
            for _, r in spikes.iterrows():
                alerts.append({
                    "í‚¤ì›Œë“œ": col.replace("_ì¦ê°ë¥ (%)", ""),
                    "ë‚ ì§œ": r["date"].date(),
                    "ìœ í˜•": "ê¸‰ë“±" if r[col] > 0 else "ê¸‰ë½",
                    "ë³€ë™ë¥ (%)": round(r[col], 1)
                })

        alert_df = pd.DataFrame(alerts)

        if alert_df.empty:
            st.info("âœ… ê¸‰ë³€ ë³€í™” ì—†ìŒ.")
        else:
            if view_mode == "ì „ì²´ ìš”ì•½ ë³´ê¸°":
                st.warning(f"âš ï¸ ê°ì§€ëœ ê¸‰ë³€ ì´ë²¤íŠ¸ {len(alert_df)}ê±´")
                st.dataframe(alert_df, width='stretch')
                summary = alert_df.groupby(["í‚¤ì›Œë“œ", "ìœ í˜•"]).size().unstack(fill_value=0)
                st.markdown("#### ğŸ“Š í‚¤ì›Œë“œë³„ ê¸‰ë“±/ê¸‰ë½ ìš”ì•½")
                st.dataframe(summary, width='stretch')
            else:
                selected_kw = st.selectbox("ğŸ” í‚¤ì›Œë“œ ì„ íƒ", sorted(df2.columns))
                kw_alerts = alert_df[alert_df["í‚¤ì›Œë“œ"] == selected_kw]
                if kw_alerts.empty:
                    st.info(f"{selected_kw} í‚¤ì›Œë“œì—ì„œ ê¸‰ë³€ ì—†ìŒ.")
                else:
                    st.dataframe(kw_alerts, width='stretch')
                    fig_kw = px.line(df2.reset_index(), x="date", y=selected_kw, title=f"{selected_kw} ê¸‰ë“±Â·ê¸‰ë½ êµ¬ê°„")
                    for _, r in kw_alerts.iterrows():
                        color = "red" if r["ìœ í˜•"] == "ê¸‰ë“±" else "blue"
                        fig_kw.add_vline(x=r["ë‚ ì§œ"], line_dash="dot", line_color=color)
                    fig_kw.update_layout(**PLOTLY_STYLE)
                    st.plotly_chart(fig_kw, width='stretch')

        st.divider()
        scaled = df2.copy()
        for col in df2.columns:
            minv, maxv = scaled[col].min(), scaled[col].max()
            scaled[col] = (scaled[col] - minv) / (maxv - minv) if maxv != minv else 0
        scaled = scaled.reset_index()
        df_scaled_long = scaled.melt(id_vars="date", var_name="metric", value_name="value")
        fig_scaled = px.line(df_scaled_long, x="date", y="value", color="metric", title="ì •ê·œí™”(0~1) ì¶”ì„¸")
        fig_scaled.update_layout(**PLOTLY_STYLE)
        st.plotly_chart(fig_scaled, width='stretch')

    # --- íƒ­ 3: ìƒê´€ ë¶„ì„ ---
    with tab3:
        st.caption("í‚¤ì›Œë“œ ê°„ ê²€ìƒ‰ íŒ¨í„´ ìœ ì‚¬ë„ë¥¼ ìƒê´€ê³„ìˆ˜ ë° ë„¤íŠ¸ì›Œí¬ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
        st.subheader("ğŸ”— ìƒê´€ê´€ê³„ ë¶„ì„")

        # ê¸°ë³¸ ìƒê´€ ë¶„ì„
        corr = df.set_index("date").corr()
        st.dataframe(corr.style.background_gradient(cmap="RdYlGn"), width='stretch')
        fig_corr = px.imshow(corr, text_auto=True, aspect="auto", title="Correlation Heatmap", color_continuous_scale="RdBu_r")
        fig_corr.update_layout(**PLOTLY_STYLE)
        st.plotly_chart(fig_corr, width='stretch')

        st.markdown("### ğŸ•¸ï¸ ë„¤íŠ¸ì›Œí¬ ìƒê´€ ê·¸ë˜í”„")
        threshold_net = st.slider("ìƒê´€ê³„ìˆ˜ ì„ê³„ê°’", 0.0, 1.0, 0.6, 0.05)
        G = nx.Graph()
        for i in corr.columns:
            for j in corr.columns:
                if i != j and abs(corr.loc[i, j]) >= threshold_net:
                    G.add_edge(i, j, weight=corr.loc[i, j])

        if len(G.edges) == 0:
            st.info(f"ì„ê³„ê°’ {threshold_net} ì´ìƒì¸ ìƒê´€ ì—†ìŒ.")
        else:
            pos = nx.spring_layout(G, seed=42)
            edge_x, edge_y, edge_color = [], [], []
            for u, v, d in G.edges(data=True):
                x0, y0 = pos[u]
                x1, y1 = pos[v]
                edge_x += [x0, x1, None]
                edge_y += [y0, y1, None]
                color = "rgba(255,0,0,0.3)" if d["weight"] > 0 else "rgba(0,0,255,0.3)"
                edge_color.append(color)

            edge_trace = go.Scatter(x=edge_x, y=edge_y, mode="lines", line=dict(width=2, color="lightgray"))
            node_x, node_y = zip(*[pos[n] for n in G.nodes()])
            node_trace = go.Scatter(
                x=node_x, y=node_y, mode="markers+text", text=list(G.nodes()),
                textposition="top center", marker=dict(size=25, color="#90CAF9", line=dict(width=2, color="#1565C0"))
            )
            fig_net = go.Figure(data=[edge_trace, node_trace])
            fig_net.update_layout(title=f"í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬ (|r| â‰¥ {threshold_net})", **PLOTLY_STYLE)
            st.plotly_chart(fig_net, width='stretch')

        # í‚¤ì›Œë“œ ê°„ êµì°¨ ìƒê´€ ë¶„ì„
        st.divider()
        st.subheader("ğŸ”¬ í‚¤ì›Œë“œ ê°„ êµì°¨ ìƒê´€ ë¶„ì„ (Cross-Correlation)")
        st.caption("ë‘ í‚¤ì›Œë“œ ê²€ìƒ‰ëŸ‰ì˜ ì‹œê°„ ì§€ì—°(Lag)ì— ë”°ë¥¸ ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬ ì„ í–‰/í›„í–‰ ê´€ê³„ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.")

        # í‚¤ì›Œë“œ ì„ íƒ
        kw_list = [c for c in df.columns if c != "date"]
        col_ccf_select = st.columns(2)
        with col_ccf_select[0]:
            kw_a = st.selectbox("í‚¤ì›Œë“œ A (Xì¶•)", kw_list, index=0)
        with col_ccf_select[1]:
            # ê¸°ë³¸ì ìœ¼ë¡œ Aì™€ ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì„ íƒí•˜ë„ë¡ ì„¤ì •
            default_index = 1 if len(kw_list) > 1 and kw_list[0] == kw_a else 0
            kw_b = st.selectbox("í‚¤ì›Œë“œ B (Yì¶•)", kw_list, index=default_index)

        max_lag = st.slider("ìµœëŒ€ ì§€ì—° ê¸°ê°„ (Lag, ì¼)", 7, min(30, len(df)//2 - 1), 14, 1)

        if kw_a == kw_b:
            st.warning("âš ï¸ êµì°¨ ìƒê´€ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ì„œë¡œ ë‹¤ë¥¸ ë‘ í‚¤ì›Œë“œë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
        else:
            df_ccf = df.set_index("date").dropna()
            if len(df_ccf) > max_lag * 2:
                # CCF ê³„ì‚°
                ccf_values = ccf(df_ccf[kw_a], df_ccf[kw_b], adjusted=False)
                
                # ì§€ì—° ê°’ ë°°ì—´ ìƒì„± ë° ìµœëŒ€ ì§€ì—° ê¸°ê°„ì— ë§ê²Œ í•„í„°ë§
                full_lags = [i - (len(df_ccf) - 1) // 2 for i in range(len(ccf_values))]
                center_idx = len(ccf_values) // 2
                
                lags = full_lags[center_idx - max_lag : center_idx + max_lag + 1]
                ccf_data = ccf_values[center_idx - max_lag : center_idx + max_lag + 1]

                ccf_df = pd.DataFrame({'Lag': lags, 'CCF': ccf_data})

                # ìµœëŒ€ ìƒê´€ ê³„ìˆ˜ ì°¾ê¸°
                max_ccf_abs = ccf_df['CCF'].abs().max()
                max_row = ccf_df.loc[ccf_df['CCF'].abs().idxmax()]
                optimal_lag = int(max_row['Lag'])
                
                # Plotly ì‹œê°í™”
                fig_ccf = go.Figure(data=[
                    go.Bar(x=ccf_df['Lag'], y=ccf_df['CCF'], marker_color='#E91E63')
                ])

                # ìµœì  ì§€ì—°ì— ìˆ˜ì§ì„  ì¶”ê°€
                fig_ccf.add_vline(x=optimal_lag, line_width=2, line_dash="dash", line_color="#FFC107")
                
                # ìœ ì˜ì„± ê²½ê³„ì„  (ëŒ€ëµì ì¸ 95% ì‹ ë¢° êµ¬ê°„) ì¶”ê°€
                conf_level = 1.96 / (len(df_ccf) ** 0.5)
                fig_ccf.add_hline(y=conf_level, line_dash="dot", line_color="#4CAF50")
                fig_ccf.add_hline(y=-conf_level, line_dash="dot", line_color="#4CAF50")
                
                fig_ccf.update_layout(
                    title=f"{kw_a} â†” {kw_b} êµì°¨ ìƒê´€ í•¨ìˆ˜ (CCF)",
                    xaxis_title=f"ì§€ì—° (Lag, ì¼) | +Lag: {kw_a}ê°€ {kw_b}ë¥¼ ì„ í–‰",
                    yaxis_title="êµì°¨ ìƒê´€ ê³„ìˆ˜",
                    **PLOTLY_STYLE,
                )

                st.plotly_chart(fig_ccf, width='stretch')

                st.markdown("#### ğŸ” ë¶„ì„ ê²°ê³¼")
                if abs(max_row['CCF']) > conf_level:
                    analysis_result = ""
                    if optimal_lag > 0:
                        analysis_result = f"**{kw_a}**ì˜ ê²€ìƒ‰ëŸ‰ íŒ¨í„´ì´ **{abs(optimal_lag)}ì¼** **ë¨¼ì €** ë°œìƒí•œ í›„, **{kw_b}**ì˜ ê²€ìƒ‰ íŒ¨í„´ê³¼ ê°€ì¥ ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§‘ë‹ˆë‹¤. (ì„ í–‰ ì§€í‘œ: **{kw_a}**)"
                    elif optimal_lag < 0:
                        analysis_result = f"**{kw_b}**ì˜ ê²€ìƒ‰ëŸ‰ íŒ¨í„´ì´ **{abs(optimal_lag)}ì¼** **ë¨¼ì €** ë°œìƒí•œ í›„, **{kw_a}**ì˜ ê²€ìƒ‰ íŒ¨í„´ê³¼ ê°€ì¥ ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§‘ë‹ˆë‹¤. (ì„ í–‰ ì§€í‘œ: **{kw_b}**)"
                    else:
                        analysis_result = f"**{kw_a}**ì™€ **{kw_b}**ëŠ” **ë™ì¼ ì‹œì (Lag 0)**ì— ê°€ì¥ ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§‘ë‹ˆë‹¤."
                    
                    st.success(f"**ìµœì  ì§€ì—°: {optimal_lag}ì¼** (ìƒê´€ ê³„ìˆ˜: {max_row['CCF']:.3f})")
                    st.markdown(analysis_result)

                else:
                    st.info("ì„ íƒí•œ ë‘ í‚¤ì›Œë“œ ê°„ì— í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ êµì°¨ ìƒê´€ ê´€ê³„ëŠ” ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            else:
                st.warning("ë°ì´í„° ê¸¸ì´ê°€ ì¶©ë¶„í•˜ì§€ ì•Šê±°ë‚˜, ìµœëŒ€ ì§€ì—° ê¸°ê°„ì´ ë„ˆë¬´ ê¸¸ì–´ CCFë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ê°„ì„ ì¤„ì—¬ì£¼ì„¸ìš”.")

    # --- íƒ­ 4: ì˜ˆì¸¡ ---
    with tab4:
        st.caption("Prophet / ARIMA / Random Forest ê¸°ë°˜ ë¯¸ë˜ ê²€ìƒ‰ íŠ¸ë Œë“œ ì˜ˆì¸¡ ë° ë¹„êµ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.")
        st.subheader("ğŸ”® íŠ¸ë Œë“œ ì˜ˆì¸¡")
        model_type = st.radio("ëª¨ë¸ ì„ íƒ", ["Prophet", "ARIMA", "Random Forest"], horizontal=True)
        selected_kw = st.selectbox("ì˜ˆì¸¡í•  í‚¤ì›Œë“œ", [c for c in df.columns if c != "date"])
        days_ahead = st.slider("ì˜ˆì¸¡ ê¸°ê°„ (ì¼)", 7, 180, 30, 7)
        df_forecast = df[["date", selected_kw]].rename(columns={"date": "ds", selected_kw: "y"})

        if model_type == "Random Forest":
            st.markdown("#### ğŸŒ² Random Forest í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì„¤ì •")
            tune = st.checkbox("Bayesian Optimizatin ê¸°ë°˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹¤í–‰", value=False)

            if tune: 
                n_trials = st.slider("íƒìƒ‰ ì‹œë„ íšŸìˆ˜", 10, 50, 25, 5)
            else:
                n_trials = None

        @st.cache_data
        def run_prophet(df, days):
            model = Prophet(yearly_seasonality=True, weekly_seasonality=True)
            model.fit(df)
            future = model.make_future_dataframe(periods=days)
            forecast = model.predict(future)
            return model, forecast

        @st.cache_data
        def run_arima(df, days):
            model = ARIMA(df.set_index("ds"), order=(3, 1, 2))
            fitted = model.fit()
            future_idx = pd.date_range(df["ds"].iloc[-1], periods=days + 1, freq="D")[1:]
            forecast = fitted.forecast(steps=days)
            return pd.DataFrame({"ë‚ ì§œ": future_idx, "ì˜ˆì¸¡ê°’": forecast})

        if st.button("ğŸš€ ì˜ˆì¸¡ ì‹¤í–‰", type="primary"):
            with st.spinner("ì˜ˆì¸¡ ì¤‘..."):
                try:
                    if model_type == "Prophet":
                        model, forecast = run_prophet(df_forecast, days_ahead)
                    
                        # MAPE/RMSE ê³„ì‚°ì„ ìœ„í•œ ì‹¤ì œê°’/ì˜ˆì¸¡ê°’ ì¶”ì¶œ
                        y_true = df_forecast['y'].values
                        y_pred = forecast['yhat'].head(len(y_true)).values
                    
                        # ì˜ˆì¸¡ ì°¨íŠ¸ í‘œì‹œ (width='stretch' -> width='stretch'ë¡œ ìµœì í™”)
                        fig = go.Figure()
                        fig.add_trace(go.Scatter(x=forecast["ds"], y=forecast["yhat"], mode="lines", name="ì˜ˆì¸¡ê°’",
                                             line=dict(color="royalblue", width=2)))
                        fig.add_trace(go.Scatter(x=forecast["ds"], y=forecast["yhat_upper"], line=dict(width=0),
                                             fill=None, showlegend=False))
                        fig.add_trace(go.Scatter(x=forecast["ds"], y=forecast["yhat_lower"],
                                             fill="tonexty", fillcolor="rgba(135,206,250,0.2)", line=dict(width=0),
                                             name="ì‹ ë¢°êµ¬ê°„"))
                        fig.add_trace(go.Scatter(x=df_forecast["ds"], y=df_forecast["y"], mode="lines+markers",
                                             name="ì‹¤ì œê°’", line=dict(color="black", width=3)))
                        fig.update_layout(title=f"{selected_kw} {days_ahead}ì¼ ì˜ˆì¸¡ (Prophet)", **PLOTLY_STYLE)
                        st.plotly_chart(fig, width='stretch') # ìµœì í™” ì ìš©

                        # -------------------- ğŸŒŸ 3. ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ í‘œì‹œ (Prophet) --------------------
                        mape = mean_absolute_percentage_error(y_true, y_pred)
                        rmse = root_mean_squared_error(y_true, y_pred)
                        save_model_metrics("Prophet", selected_kw, mape, rmse)

                        st.markdown("#### ğŸŒŸ ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ")
                        col_metrics = st.columns(2)
                        col_metrics[0].metric(label="MAPE (Mean Absolute Percentage Error)", value=f"{mape:.2f}%")
                        col_metrics[1].metric(label="RMSE (Root Mean Squared Error)", value=f"{rmse:.2f}")
                        st.caption("MAPEì™€ RMSEëŠ” ì˜ˆì¸¡ ê¸°ê°„ì„ ì œì™¸í•œ ê³¼ê±° ë°ì´í„°ì— ëŒ€í•œ ëª¨ë¸ì˜ ì í•©ë„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.")
                    
                        # =========================================================
                        # âœ¨ 1. Prophet ê¸°ë°˜ ê³„ì ˆì„± ë° ì¶”ì„¸ ë¶„í•´ ì‹œê°í™” 
                        # =========================================================
                        st.divider()
                        st.subheader("âœ¨ íŠ¸ë Œë“œ ë¶„í•´ ë¶„ì„ (Prophet)")
                        st.caption("ê²€ìƒ‰ëŸ‰ ë°ì´í„°ì—ì„œ ì¥ê¸° ì¶”ì„¸, ì—°ê°„ ê³„ì ˆì„±, ì£¼ê°„ ê³„ì ˆì„±ì„ ë¶„ë¦¬í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤.")

                        # -------------------- 1. ì¥ê¸° ì¶”ì„¸ (Trend) --------------------
                        fig_trend = px.line(forecast, x="ds", y="trend", title="ì¥ê¸° ì¶”ì„¸ (Trend)",
                                        color_discrete_sequence=['#4CAF50'])
                        fig_trend.update_layout(plot_bgcolor="white", paper_bgcolor="#F5F5F5", font=dict(size=12), margin=dict(l=20, r=20, t=30, b=20), showlegend=False)
                        fig_trend.update_yaxes(title_text="ì˜í–¥ë„")
                    
                        # -------------------- 2. ì—°ê°„ ê³„ì ˆì„± (Yearly) --------------------
                        df_yearly_pattern = forecast[['ds', 'yearly']].tail(365).copy() 
                        fig_yearly = go.Figure()
                        fig_yearly.add_trace(go.Scatter(x=df_yearly_pattern["ds"], y=df_yearly_pattern["yearly"], mode="lines", name="ì—°ê°„ ê³„ì ˆì„±", line=dict(color="#2196F3")))
                        fig_yearly.update_layout(title="ì—°ê°„ ê³„ì ˆì„± (Yearly Seasonality)", plot_bgcolor="white", paper_bgcolor="#F5F5F5", font=dict(size=12), margin=dict(l=20, r=20, t=30, b=20), showlegend=False)
                        fig_yearly.update_xaxes(title_text="ë‚ ì§œ", tickformat="%m-%d") 
                        fig_yearly.update_yaxes(title_text="ì˜í–¥ë„")
                    
                        # -------------------- 3. ì£¼ê°„ ê³„ì ˆì„± (Weekly) --------------------
                        df_weekly = forecast[["ds", "weekly"]].tail(7).copy()
                        day_names_kr = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
                        df_weekly['day_name_kr'] = df_weekly['ds'].dt.day_name(locale='en').map({
                            'Monday': 'ì›”', 'Tuesday': 'í™”', 'Wednesday': 'ìˆ˜', 'Thursday': 'ëª©', 
                            'Friday': 'ê¸ˆ', 'Saturday': 'í† ', 'Sunday': 'ì¼'
                        })
                    
                        df_weekly['day_name_kr'] = pd.Categorical(df_weekly['day_name_kr'], categories=day_names_kr, ordered=True)
                        df_weekly = df_weekly.sort_values('day_name_kr')

                        fig_weekly = px.bar(df_weekly, x="day_name_kr", y="weekly", title="ì£¼ê°„ ê³„ì ˆì„± (Weekly Seasonality)",
                                        color_discrete_sequence=['#FFC107'])
                        fig_weekly.update_layout(plot_bgcolor="white", paper_bgcolor="#F5F5F5", font=dict(size=12), margin=dict(l=20, r=20, t=30, b=20), showlegend=False)
                        fig_weekly.update_xaxes(title_text="ìš”ì¼", categoryorder='array', categoryarray=day_names_kr)
                        fig_weekly.update_yaxes(title_text="ì˜í–¥ë„")
                    
                        # -------------------- 4. 3ë¶„í•  ì»¬ëŸ¼ì— ì°¨íŠ¸ í‘œì‹œ --------------------
                        cols_comp = st.columns(3)
                        with cols_comp[0]:
                            st.plotly_chart(fig_trend, width='stretch', config={'displayModeBar': False})
                        with cols_comp[1]:
                            st.plotly_chart(fig_yearly, width='stretch', config={'displayModeBar': False})
                        with cols_comp[2]:
                            st.plotly_chart(fig_weekly, width='stretch', config={'displayModeBar': False})

                    elif model_type == "ARIMA":
                        forecast_df = run_arima(df_forecast, days_ahead)
                    
                        # ARIMA ëª¨ë¸ ì„±ëŠ¥ ì¸¡ì •ì„ ìœ„í•œ ì˜ˆì¸¡ì¹˜ ì¶”ì¶œ
                        model_arima = ARIMA(df_forecast.set_index("ds"), order=(3, 1, 2))
                        fitted_arima = model_arima.fit()
                    
                        y_true = df_forecast['y'].iloc[1:].values
                        y_pred_past = fitted_arima.predict(start=1, end=len(df_forecast) - 1, dynamic=False).values
                    
                        # ì˜ˆì¸¡ ì°¨íŠ¸ í‘œì‹œ (width='stretch' -> width='stretch'ë¡œ ìµœì í™”)
                        fig = go.Figure()
                        fig.add_trace(go.Scatter(x=df_forecast["ds"], y=df_forecast["y"], mode="lines+markers",
                                             name="ì‹¤ì œê°’", line=dict(color="black", width=3)))
                        fig.add_trace(go.Scatter(x=forecast_df["ë‚ ì§œ"], y=forecast_df["ì˜ˆì¸¡ê°’"], mode="lines",
                                             name="ì˜ˆì¸¡ê°’", line=dict(color="royalblue", width=2.5, dash="dot")))
                        fig.update_layout(title=f"ARIMA ê¸°ë°˜ {selected_kw} {days_ahead}ì¼ ì˜ˆì¸¡", **PLOTLY_STYLE)
                        st.plotly_chart(fig, width='stretch') # ìµœì í™” ì ìš©
                    
                        # -------------------- ğŸŒŸ 3. ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ í‘œì‹œ (ARIMA) --------------------
                        mape = mean_absolute_percentage_error(y_true, y_pred_past)
                        rmse = root_mean_squared_error(y_true, y_pred_past)
                        save_model_metrics("ARIMA", selected_kw, mape, rmse)


                        st.markdown("#### ğŸŒŸ ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ")
                        col_metrics = st.columns(2)
                        col_metrics[0].metric(label="MAPE (Mean Absolute Percentage Error)", value=f"{mape:.2f}%")
                        col_metrics[1].metric(label="RMSE (Root Mean Squared Error)", value=f"{rmse:.2f}")
                        st.caption("MAPEì™€ RMSEëŠ” í›ˆë ¨ ë°ì´í„°ì— ëŒ€í•œ ëª¨ë¸ì˜ ì í•©ë„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.")
                    elif model_type == "Random Forest":
                        tuned_model = None
                        st.subheader("ğŸŒ² Random Forest ì˜ˆì¸¡ ë° Bayesian íŠœë‹")
                        
                        if tune:
                            with st.spinner("Optuna Bayesian Optimization íŠœë‹ ì¤‘... â³"):
                                train_df_rf = create_features(df_forecast.copy())
                                features_x_rf = [c for c in train_df_rf.columns if c not in ['ds', 'y']]
                                X_train_rf, y_train_rf = train_df_rf[features_x_rf], train_df_rf['y']
                                
                                best_model, best_params, best_score = tune_random_forest_bayesian(X_train_rf, y_train_rf, n_trials=n_trials)
                            
                            st.success("ğŸ¯ Bayesian Optimization ì™„ë£Œ!")
                            st.json(best_params)
                            st.caption(f"ìµœì  MSE: {best_score:.4f}")
                            tuned_model = best_model
                            
                            # ìµœì  ëª¨ë¸ì„ ì‚¬ìš©í–ˆìœ¼ë¯€ë¡œ, X_train_rfë¡œ ê³¼ê±° ì˜ˆì¸¡ê°’ ì¬ê³„ì‚°
                            y_pred_past_rf = tuned_model.predict(X_train_rf)
                        else:
                            # íŠœë‹ ì•ˆ í•  ê²½ìš° ê¸°ë³¸ ëª¨ë¸ë¡œ ê³¼ê±° ì˜ˆì¸¡ê°’ ê³„ì‚°
                            model_default = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
                            train_df_rf = create_features(df_forecast.copy())
                            features_x_rf = [c for c in train_df_rf.columns if c not in ['ds', 'y']]
                            X_train_rf, y_train_rf = train_df_rf[features_x_rf], train_df_rf['y']
                            model_default.fit(X_train_rf, y_train_rf)
                            y_pred_past_rf = model_default.predict(X_train_rf)
                            tuned_model = model_default

                        # â­ ì˜ˆì¸¡ ì‹¤í–‰ (run_random_forest í•¨ìˆ˜ì— íŠœë‹ëœ ëª¨ë¸ ì „ë‹¬)
                        forecast_df, y_true, y_pred_past, feature_importances, features = run_random_forest(df_forecast, days_ahead, tuned_model=tuned_model)

                        # 2. ì˜ˆì¸¡ ì°¨íŠ¸ í‘œì‹œ
                        fig = go.Figure()
                        fig.add_trace(go.Scatter(x=df_forecast["ds"], y=df_forecast["y"], mode="lines+markers",
                                                 name="ì‹¤ì œê°’", line=dict(color="black", width=3)))
                        fig.add_trace(go.Scatter(x=forecast_df["ë‚ ì§œ"], y=forecast_df["ì˜ˆì¸¡ê°’"], mode="lines",
                                                 name="ì˜ˆì¸¡ê°’", line=dict(color="#FF5722", width=2.5, dash="dot"))) # ì£¼í™©ìƒ‰ ê³„ì—´
                        fig.update_layout(title=f"Random Forest ê¸°ë°˜ {selected_kw} {days_ahead}ì¼ ì˜ˆì¸¡", **PLOTLY_STYLE)
                        st.plotly_chart(fig, width='stretch')
                        
                        # 3. ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ í‘œì‹œ
                        mape = mean_absolute_percentage_error(y_true, y_pred_past) # y_pred_pastëŠ” íŠœë‹ ê²°ê³¼ ë°˜ì˜
                        rmse = root_mean_squared_error(y_true, y_pred_past)
                        save_model_metrics("Random Forest", selected_kw, mape, rmse) # â­ í‚¤ì›Œë“œ ì¸ì ì¶”ê°€
        
                        st.markdown("#### ğŸŒŸ ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ")
                        col_metrics = st.columns(2)
                        col_metrics[0].metric(label="MAPE (Mean Absolute Percentage Error)", value=f"{mape:.2f}%")
                        col_metrics[1].metric(label="RMSE (Root Mean Squared Error)", value=f"{rmse:.2f}")
                        st.caption("MAPEì™€ RMSEëŠ” í›ˆë ¨ ë°ì´í„°ì— ëŒ€í•œ ëª¨ë¸ì˜ ì í•©ë„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.")

                        # -------------------- ğŸ’¡ í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„ ì‹œê°í™” --------------------
                        st.divider()
                        st.subheader("ğŸ’¡ í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„ (Random Forest)")
                        st.caption("ëª¨ë¸ ì˜ˆì¸¡ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹œ ì‹œê°„ í”¼ì²˜ì˜ ê¸°ì—¬ë„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
                        
                        importance_df = pd.DataFrame({
                            'Feature': features,
                            'Importance': feature_importances
                        }).sort_values(by='Importance', ascending=True)
                        
                        # Plotly ë§‰ëŒ€ ê·¸ë˜í”„ë¡œ ì‹œê°í™”
                        fig_import = px.bar(
                            importance_df,
                            x='Importance',
                            y='Feature',
                            orientation='h',
                            title='ê²€ìƒ‰ëŸ‰ ì˜ˆì¸¡ì— ê¸°ì—¬í•œ ì‹œê°„ ìš”ì¸',
                            color='Importance',
                            color_continuous_scale=px.colors.sequential.Teal
                        )
                        fig_import.update_layout(
                            plot_bgcolor='white', paper_bgcolor='#F5F5F5',
                            margin=dict(l=20, r=20, t=30, b=20),
                            font=dict(size=12)
                        )
                        st.plotly_chart(fig_import, width='stretch', config={'displayModeBar': False})
                       
                except Exception as e:
                    st.error(f"âŒ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")

    # --- íƒ­ 5: ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ---
    with tab5:
        st.subheader("ğŸ“Š ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ ëŒ€ì‹œë³´ë“œ")

        if "model_metrics" not in st.session_state or len(st.session_state["model_metrics"]) == 0:
            st.info("ì•„ì§ ì €ì¥ëœ ëª¨ë¸ ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì˜ˆì¸¡ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        else:
            df_metrics = pd.DataFrame(st.session_state["model_metrics"])
            
            available_keywords = df_metrics["í‚¤ì›Œë“œ"].unique()
            try:
                default_index = list(available_keywords).index(selected_kw)
            except ValueError:
                default_index = 0
            selected_comparison_kw = st.selectbox("í‚¤ì›Œë“œ ì„ íƒ (ë¹„êµ ëŒ€ìƒ)", available_keywords, index=default_index)

            df_filtered = df_metrics[df_metrics["í‚¤ì›Œë“œ"] == selected_comparison_kw]
            st.dataframe(df_filtered, width='stretch')
            
            if not df_filtered.empty:
                # ìµœì  ëª¨ë¸ ì°¾ê¸°
                best_row = df_filtered.loc[df_filtered["RMSE"].idxmin()]
                st.success(f"ğŸ† í‚¤ì›Œë“œ **'{selected_comparison_kw}'**ì— ëŒ€í•œ ìµœì  ëª¨ë¸: **{best_row['ëª¨ë¸ëª…']}** (RMSE {best_row['RMSE']:.4f})")

                # ì‹œê°í™”(RMSE / MAPE ë¹„êµ)
                st.markdown("#### RMSE ë¹„êµ")
                fig_rmse = px.bar(df_filtered, x="ëª¨ë¸ëª…", y="RMSE", color="ëª¨ë¸ëª…",
                                    text="RMSE", title=f"'{selected_comparison_kw}' ëª¨ë¸ë³„ RMSE ë¹„êµ", color_discrete_sequence=px.colors.qualitative.Set2)
                fig_rmse.update_layout(**PLOTLY_STYLE)
                st.plotly_chart(fig_rmse, width='stretch')

                st.markdown("### MAPE ë¹„êµ")
                fig_mape = px.bar(df_filtered, x="ëª¨ë¸ëª…", y="MAPE(%)", color="ëª¨ë¸ëª…",
                                    text="MAPE(%)", title=f"'{selected_comparison_kw}' ëª¨ë¸ë³„ MAPE ë¹„êµ", color_discrete_sequence=px.colors.qualitative.Pastel)
                fig_mape.update_layout(**PLOTLY_STYLE)
                st.plotly_chart(fig_mape, width='stretch')
            else:
                st.info(f"í‚¤ì›Œë“œ '{selected_comparison_kw}'ì— ëŒ€í•´ ì €ì¥ëœ ì¸¡ì •ê°’ì´ ì—†ìŠµë‹ˆë‹¤. ì˜ˆì¸¡ì„ ì‹¤í–‰í•˜ì—¬ ì €ì¥í•˜ì„¸ìš”.")

    # --- íƒ­ 6: ë‹¤ìš´ë¡œë“œ ---
    with tab6:
        st.subheader("â¬‡ï¸ ë°ì´í„° ë° ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ")

        csv = df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ğŸ’¾ ìµœì‹  ë°ì´í„° ë‹¤ìš´ë¡œë“œ", csv, "trend_data_latest.csv", "text/csv")

        st.divider()
        st.markdown("ğŸ’¾ ëª¨ë¸ ì„±ëŠ¥ ë¦¬í¬íŠ¸ (PDF ìƒì„±)")

        if "model_metrics" not in st.session_state or len(st.session_state["model_metrics"]) == 0:
            st.info("ëª¨ë¸ ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì˜ˆì¸¡ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        else:
            if st.button("ğŸ§¾ PDF ë¦¬í¬íŠ¸ ìƒì„±", type="primary"):
                try:
                    from io import BytesIO
                    from reportlab.pdfgen import canvas
                    from reportlab.lib.pagesizes import A4
                    from reportlab.lib.units import cm
                    from reportlab.lib import colors

                    buffer = BytesIO()
                    c = canvas.Canvas(buffer, pagesize=A4)
                    width, height = A4

                    c.setFont("HYSMyeongJo-Medium", 18)
                    c.setFillColor(colors.HexColor("#0D47A1"))
                    c.drawCentredString(width / 2, height - 2 * cm, "TrendLens ëª¨ë¸ ì„±ëŠ¥ ë¦¬í¬íŠ¸")

                    c.setFont("HYSMyeongJo-Medium", 11)
                    c.setFillColor(colors.black)
                    c.drawString(2 * cm, height - 3 * cm, f"ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

                    data = pd.DataFrame(st.session_state["model_metrics"])
                    start_y = height - 4 * cm
                    c.setFont("HYSMyeongJo-Medium", 12)
                    c.drawString(2 * cm, start_y, "ëª¨ë¸ë³„ ì„±ëŠ¥ ìš”ì•½:")

                    start_y -= 0.7 * cm
                    c.setFont("HYSMyeongJo-Medium", 10)
                    for i, row in data.iterrows():
                        line = f"- [{row['í‚¤ì›Œë“œ']}] {row['ëª¨ë¸ëª…']} | MAPE: {row['MAPE(%)']}% | RMSE: {row['RMSE']} | {row['ê¸°ë¡ì‹œê°„']}"
                        c.drawString(2.2 * cm, start_y, line)
                        start_y -= 0.5 * cm
                        if start_y < 2 * cm:  # í˜ì´ì§€ ë„˜ê¹€ ì²˜ë¦¬
                            c.showPage()
                            c.setFont("HYSMyeongJo-Medium", 10)
                            start_y = height - 3 * cm

                    c.setFont("HYSMyeongJo-Medium", 9)
                    c.setFillColor(colors.gray)
                    c.drawString(2 * cm, 1.5 * cm, "Generated by TrendLens | Naver Trend Analysis Dashboard")

                    c.save()
                    buffer.seek(0)

                    st.download_button(
                        label="ğŸ“¥ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ (PDF)",
                        data=buffer,
                        file_name=f"TrendLens_Report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                        mime="application/pdf"
                    )
                    st.success("âœ… PDF ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
                except Exception as e:
                    st.error(f"PDF ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

else:
    st.info("ì¢Œì¸¡ì—ì„œ ê²€ìƒ‰ì–´së¥¼ ì…ë ¥í•˜ê³  'ì—…ë°ì´íŠ¸'ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

# ===============================
# â° ìë™ ì—…ë°ì´íŠ¸ ìŠ¤ì¼€ì¤„ëŸ¬
# ===============================
scheduler = BackgroundScheduler()
scheduler.add_job(auto_update_job, "interval", hours=24)
scheduler.start()
atexit.register(lambda: scheduler.shutdown())